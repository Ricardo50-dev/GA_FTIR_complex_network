{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN4WrLGxoJYe6/ScJWbhrX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ricardo50-dev/GA_FTIR_complex_network/blob/main/AG_FTIR_Redes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importando bibliotecas**"
      ],
      "metadata": {
        "id": "UmPquHiuhA_8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YThOB80gX3e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import igraph as ig\n",
        "import rampy as rp\n",
        "from copy import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from random import randrange\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.preprocessing import minmax_scale, normalize\n",
        "from sklearn.metrics import euclidean_distances\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import pairwise, confusion_matrix\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.signal import gauss_spline\n",
        "from sklearn.neighbors import KDTree\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install igraph\n",
        "!pip install rampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8Pn5yVXghqY",
        "outputId": "06852558-9343-495c-dce9-1ffc63e64be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting igraph\n",
            "  Downloading igraph-0.11.3-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable>=1.6.2 (from igraph)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph\n",
            "Successfully installed igraph-0.11.3 texttable-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**População**"
      ],
      "metadata": {
        "id": "3ip56XoghSjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inicia_populacao(Tpop, wavs):\n",
        "  Pop = np.zeros((Tpop,wavs.size))\n",
        "  for i in range(Tpop):\n",
        "    Pop[i] = np.random.randint(2, size=wavs.size)\n",
        "  return Pop"
      ],
      "metadata": {
        "id": "dMpxXXF7hqmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Leitura dos dados**"
      ],
      "metadata": {
        "id": "mBG2CSE2h1gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ftir_data(filename): #Leitura do arquivo FTIR\n",
        "    data = np.loadtxt(filename)\n",
        "    return data[:,:-1], data[:,-1].astype(int)\n",
        "\n",
        "#def main(): Iniciando o programa.\n",
        "wavsname = \"wavenumbers.dat\"\n",
        "filename = \"dataset_cancboca_bruto.dat\"\n",
        "\n",
        "#load input data\n",
        "X, y = load_ftir_data(filename)\n",
        "y = np.where(y <= -1, 0, y)\n",
        "#load wavs size\n",
        "wavs = np.loadtxt(wavsname)"
      ],
      "metadata": {
        "id": "Tn7p1QBHh0-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parâmetros do AG**"
      ],
      "metadata": {
        "id": "XuHCAXPhi0jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tpop = 10\n",
        "Taxa_mut = 0.2\n",
        "Geracoes = 10\n",
        "T_cross = 0.4\n",
        "k = 7\n",
        "med_rede = \"clustcoefficient\"\n",
        "#modelo pode ser SVM, RF ou LDA"
      ],
      "metadata": {
        "id": "BE2TQR0-i4ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inicia população**"
      ],
      "metadata": {
        "id": "0RB21IT8jCYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pop = inicia_populacao(Tpop, wavs)"
      ],
      "metadata": {
        "id": "spNSkCuejCJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(Pop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of-DVMJ6jKlw",
        "outputId": "f2f8242e-8067-4c4c-96a5-33c007fec230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1867)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mutação, Crossover e Torneio**"
      ],
      "metadata": {
        "id": "B6cAY3o4kt0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Mutacao(pop, Taxa_mut):\n",
        "  for i in range(pop.shape[0]):\n",
        "    sorteio = np.random.randint(pop.shape[1]-1, size=1) # Sorteia uma posição do array\n",
        "    p = random.random() #Probabiliade da mutação\n",
        "\n",
        "    if p < Taxa_mut :\n",
        "      if pop[i][sorteio] == 1:\n",
        "        pop[i][sorteio] = 0\n",
        "      else:\n",
        "        pop[i][sorteio] = 1\n",
        "\n",
        "  return pop"
      ],
      "metadata": {
        "id": "239S-ZFzk8O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selecao_torneio(pop, k, Tpop):\n",
        "  participantes = np.random.randint(Tpop, size=k) #Sorteia k individuos para o torneio\n",
        "  best = 0\n",
        "  for i in range (k):\n",
        "    fit = pop[participantes[i]][-1]\n",
        "    if fit > best:\n",
        "      best = fit\n",
        "      ganhador = pop[participantes[i]]\n",
        "\n",
        "  return ganhador"
      ],
      "metadata": {
        "id": "8WlJBq84wz-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crossover(pai1, pai2):\n",
        "  x = np.random.randint(max(pai1.size,pai2.size), size=1) # Sorteia uma posição do array\n",
        "  x = int(x)\n",
        "  tmp = pai2[:x].copy()\n",
        "  pai2[:x], pai1[:x]  = pai1[:x], tmp\n",
        "\n",
        "  filhos = np.vstack([pai1,pai2])\n",
        "\n",
        "  return filhos"
      ],
      "metadata": {
        "id": "uewKi_B1y3bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gerador da rede, Medidas de rede e Funções complementares**"
      ],
      "metadata": {
        "id": "0b3lqtut1Tex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graphgen(k, X, y, med_rede):\n",
        "\n",
        "    # pega o num de classes\n",
        "    numclasses = len(np.unique(y))\n",
        "\n",
        "    # X = gauss_spline(X, len(X))\n",
        "\n",
        "    euclidean_dist = pairwise.cosine_similarity(X)\n",
        "\n",
        "    # preenche a diagonal principal com valor infinito\n",
        "    np.fill_diagonal(euclidean_dist, np.inf)\n",
        "\n",
        "    # ordena as distancias por objeto em ordem ascendente\n",
        "    #print(euclidean_dist)\n",
        "    ind_ranking = np.argsort(euclidean_dist, axis=1)[:, :k]\n",
        "\n",
        "    # inicializa uma mascara com False, num de objetos x k\n",
        "    mask = np.zeros((len(X), k)).astype(int)\n",
        "\n",
        "    # preenche os campos True da mascara, vizinho mais proximos que sao da mesma clase\n",
        "    lista_grafos = []\n",
        "    for i in range(len(ind_ranking)):\n",
        "        mask[i] = (y[ind_ranking[i]] == y[i])\n",
        "\n",
        "    # captura os indices True da mascara, linha e coluna\n",
        "    links = mask.nonzero()\n",
        "\n",
        "    # atribui os indices das linhas\n",
        "    sources = links[0]\n",
        "\n",
        "    # atribui o indice real dos objetos das colunas\n",
        "    targets = ind_ranking[links]\n",
        "\n",
        "    # inicializa funcao para mapeamento dos vertices\n",
        "    map_vertices = np.zeros(len(ind_ranking)).astype(int) - 1\n",
        "\n",
        "    # inicializa variavel para guardar o calculo das medidas\n",
        "    measures = np.zeros((numclasses, 1))\n",
        "    for l in range(numclasses):\n",
        "\n",
        "        # captura todos os objetos em sources que pertencem a classe l\n",
        "        lsources = np.where(y[sources] == l)[0]\n",
        "\n",
        "        # captura todos os objetos da base que pertencem a classe l\n",
        "        all_vertices = np.where(y == l)[0]\n",
        "\n",
        "        # recebe todos os objetos da classe l que estao conectados\n",
        "        unique_vertices = np.unique(\n",
        "            np.append(sources[lsources], targets[lsources])).astype(int)\n",
        "\n",
        "        # recebe os demais objetos da classe l que nao estao conectados\n",
        "        unique_vertices = np.unique(\n",
        "            np.append(unique_vertices, all_vertices)).astype(int)\n",
        "\n",
        "        # popula a funcao de mapeamento dos vertices com os objetos da classe l\n",
        "        map_vertices[unique_vertices] = np.arange(\n",
        "            len(unique_vertices)).astype(int)\n",
        "\n",
        "        # cria o grafo para classe l\n",
        "        subg = ig.Graph(len(unique_vertices), list(zip(map_vertices[sources[lsources]].astype(\n",
        "            int), map_vertices[targets[lsources]].astype(int))))\n",
        "\n",
        "        # popula a lista de grafos\n",
        "        lista_grafos.append(subg)\n",
        "\n",
        "        # calcula as medidas de rede associadas ao grafo l\n",
        "        if med_rede == 'assortativity':\n",
        "            measures[l, 0] = Assortativity(subg)\n",
        "        elif med_rede == 'clustcoefficient':\n",
        "            measures[l, 0] = ClustCoefficient(subg)\n",
        "        elif med_rede == 'avgdegree':\n",
        "            measures[l, 0] = AvgDegree(subg)\n",
        "        elif med_rede == 'betweenness':\n",
        "            measures[l, 0] = Betweenness(subg)\n",
        "        elif med_rede == 'avgpathlength':\n",
        "            measures[l, 0] = AvgPathLength(subg)\n",
        "        elif med_rede == 'closeness':\n",
        "            measures[l, 0] = Closeness(subg)\n",
        "        '''measures[l, 0] = Assortativity(subg)\n",
        "        measures[l, 1] = ClustCoefficient(subg)\n",
        "        measures[l, 2] = AvgDegree(subg)\n",
        "        measures[l, 3] = Betweenness(subg)\n",
        "        measures[l, 4] = AvgPathLength(subg)\n",
        "        measures[l, 5] = Closeness(subg)'''\n",
        "\n",
        "    return lista_grafos, map_vertices, measures"
      ],
      "metadata": {
        "id": "Mvy-t2kD1Mp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Assortativity(graph):\n",
        "    return ig.Graph.assortativity_degree(graph)\n",
        "\n",
        "\n",
        "def ClustCoefficient(graph):\n",
        "    return ig.Graph.transitivity_avglocal_undirected(graph)\n",
        "\n",
        "\n",
        "def AvgDegree(graph):\n",
        "    return np.mean(ig.Graph.degree(graph))\n",
        "\n",
        "\n",
        "def Betweenness(graph):\n",
        "    return np.mean(ig.Graph.betweenness(graph))\n",
        "\n",
        "\n",
        "def AvgPathLength(graph):\n",
        "    return ig.Graph.average_path_length(graph)\n",
        "\n",
        "\n",
        "def Closeness(graph):\n",
        "    return np.mean(ig.Graph.closeness(graph))"
      ],
      "metadata": {
        "id": "PC38IDII1juJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deep_copy_graphs(lista_grafos):\n",
        "    newlist = []\n",
        "    for i in range(len(lista_grafos)):\n",
        "        newlist.append(ig.Graph.copy(lista_grafos[i]))\n",
        "\n",
        "    return newlist\n",
        "\n",
        "def sample_smoothing_differentiation(X):\n",
        "    return savgol_filter(X, 25, 4, 2, axis=1)\n",
        "\n",
        "\n",
        "def sample_normalization(X):\n",
        "    return X/(np.linalg.norm(X,2,axis=1).reshape(-1,1))\n",
        "\n",
        "\n",
        "def sample_amida1_normalization(X, amida1_ids):\n",
        "    return X/(np.max(X[:,amida1_ids],axis=1).reshape(-1,1))"
      ],
      "metadata": {
        "id": "Gadh78mm1nsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função Fitness**\n",
        "\n",
        "fit_rede = gera um dicionario contento valores de ACC, SEN, ESP, STD, MD"
      ],
      "metadata": {
        "id": "JN_eOQ57zoO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_rede(X, y, med_rede, k):\n",
        "    NN1 = True\n",
        "    acc1NN = []\n",
        "\n",
        "    # matriz para os resultados, 30 analises, 15 valor de k, e 6 medidas\n",
        "    acc_results = np.zeros((30, 17, 1))\n",
        "    sen_results = np.zeros((30, 17, 1))\n",
        "    esp_results = np.zeros((30, 17, 1))\n",
        "\n",
        "    # rodar para cada valor de k de 1 a 15\n",
        "    #for k in range(1, 16):\n",
        "    k = 13\n",
        "    # seta um valor seed para gerar os numeros pseudo-aleatorios\n",
        "    np.random.seed(1000)\n",
        "\n",
        "    # KNN para construcao da base com k = 1\n",
        "    knn = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "    # validacao cruzada, a base eh dividida em 10 partes e cada uma eh executada 3 vezes como treino\n",
        "    rskf = RepeatedStratifiedKFold(\n",
        "        n_splits=10, n_repeats=3, random_state=10)\n",
        "\n",
        "    # Separa os dados de treino e teste utilizando validacao cruzada\n",
        "    for b1, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # conta quantas vezes cada valor de y apareceu\n",
        "        # 1NN - baseline\n",
        "        if NN1:\n",
        "            # quais sao as classes para serem classificada?\n",
        "            knn.fit(X_train, y_train)\n",
        "\n",
        "            # insere o resultado do knn em uma lista\n",
        "            acc1NN.append(knn.score(X_test, y_test))\n",
        "            # print(\"1: \", acc)\n",
        "\n",
        "        # Network measures\n",
        "        # Define a matriz predicted com o tamanho do teste, a classe, e o numero de medidas\n",
        "        predicted = np.ones((len(X_test), len(np.unique(y)), 1)) * np.inf\n",
        "\n",
        "        # manda para a funcao graphgen, o valor de k, e\n",
        "        lista_grafos, map_vertices, measures = graphgen(\n",
        "            k, X_train, y_train, med_rede)\n",
        "        # calcula a distancia euclidiana entre os pares de teste e o objeto\n",
        "        tree = KDTree(X_train)\n",
        "        dist, ind = tree.query(X_test, k=3)\n",
        "\n",
        "        for i in range(len(X_test)):\n",
        "\n",
        "            # ordena as distancias por objeto em ordem ascendente\n",
        "            ids = ind[i - 1]\n",
        "            #ids = np.argsort(dist[i])[:k]\n",
        "\n",
        "            # newgraph recebe uma copia de lista_grafos\n",
        "            newgraph = deep_copy_graphs(lista_grafos)\n",
        "\n",
        "            # j eh o indice do objeto de treino e c a classe dele\n",
        "            for j, c in enumerate(y_train[ids]):\n",
        "                # cria um id para o novo vertice no grafo da classe c\n",
        "                newid = lista_grafos[c].vcount()\n",
        "                # adiciona o vertice do grafo para o novo objeto\n",
        "                newgraph[c].add_vertex(newid)\n",
        "                # verifica se o vertice em que o novo objeto sera conectado ja esta no grafo\n",
        "                if map_vertices[ids[j]] > newid:\n",
        "                    newgraph[c].add_vertex(map_vertices[ids[j]])\n",
        "\n",
        "                newgraph[c].add_edge(newid, map_vertices[ids[j]])\n",
        "\n",
        "            # para cada uma das classes\n",
        "            for c in np.unique(y_train[ids]):\n",
        "                subg = newgraph[c]\n",
        "                # calcula as medidas\n",
        "                if med_rede == 'assortativity':\n",
        "                    predicted[i, c, 0] = abs(Assortativity(subg) - measures[c, 0])\n",
        "                elif med_rede == 'clustcoefficient':\n",
        "                    predicted[i, c, 0] = abs(ClustCoefficient(subg) - measures[c, 0])\n",
        "                elif med_rede == 'avgdegree':\n",
        "                    predicted[i, c, 0] = abs(AvgDegree(subg) - measures[c, 0])\n",
        "                elif med_rede == 'betweenness':\n",
        "                    predicted[i, c, 0] = abs(Betweenness(subg) - measures[c, 0])\n",
        "                elif med_rede == 'avgpathlength':\n",
        "                    predicted[i, c, 0] = abs(\n",
        "                        AvgPathLength(subg) - measures[c, 0])\n",
        "                elif med_rede == 'closeness':\n",
        "                    predicted[i, c, 0] = abs(Closeness(subg) - measures[c, 0])\n",
        "\n",
        "        # calcula a acuracia, sensibilidade e especificidade\n",
        "        Matriz = np.zeros((len(y_test),2))\n",
        "        Matriz[:,:-1] = np.tile(y_test, (1, 1)).T\n",
        "        Matriz[:,-1:] = np.argmin(predicted, axis=1)\n",
        "        matriz_conf = np.zeros((2,2))\n",
        "        tp = tn = fp = fn = 0\n",
        "        for p in range(len(y_test)):\n",
        "            for l in range(2):\n",
        "                if l == 0:\n",
        "                    ini = Matriz[p][l]\n",
        "                else:\n",
        "                    fim = Matriz[p][l]\n",
        "            if ini == fim == 1:\n",
        "                tp += 1\n",
        "            elif ini == fim == 0:\n",
        "                tn += 1\n",
        "            elif ini == 0 and fim == 1:\n",
        "                fp += 1\n",
        "            elif ini == 1 and fim == 0:\n",
        "                fn += 1\n",
        "        matriz_conf[0][0] = tp\n",
        "        matriz_conf[0][1] = fn\n",
        "        matriz_conf[1][0] = fp\n",
        "        matriz_conf[1][1] = tn\n",
        "        sensibilidade = tp/(tp + fn)\n",
        "        especificidade = tn/(fp + tn)\n",
        "        sen_results[b1, k - 1] = sensibilidade\n",
        "        esp_results[b1, k - 1] = especificidade\n",
        "        acc_results[b1, k - 1] = np.mean(np.tile(y_test, (1, 1)).T ==\n",
        "                                        np.argmin(predicted, axis=1), axis=0)\n",
        "\n",
        "    #Calcula todas a medidas avaliativas na mão\n",
        "    fit = np.max(np.mean(acc_results, axis=0))\n",
        "    std = np.max(np.std(acc_results, axis=0))\n",
        "    sen = np.max(np.mean(sen_results, axis=0))\n",
        "    esp = np.max(np.mean(esp_results, axis=0))\n",
        "    md = (sen + esp) / 2\n",
        "    #Retorna o dicionario do individuo organizadamente entre chave e valor\n",
        "    dicionarioIndividuo = dict(acc=fit, std=std, sen=sen, esp=esp, md=md)\n",
        "\n",
        "    return dicionarioIndividuo"
      ],
      "metadata": {
        "id": "wuZKsucTztda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness_pop(pop, x, y, med_rede, k):\n",
        "  fit = np.zeros([pop[:,1].size, 1],dtype=float) #Criacao da array do fit do tamanho da populacao, a matriz contem 1 coluna com pop.size linhas.\n",
        "  for i in range(pop.shape[0]):\n",
        "    ind = pop[i]\n",
        "    data = x\n",
        "    amida1_ids = np.where(np.logical_and(wavs >= 1630, wavs <= 1660))[0]\n",
        "    data = sample_amida1_normalization(data, amida1_ids)\n",
        "    data = data[:,ind[0:].nonzero()[0]]\n",
        "    resultado = fit_rede(data, y, med_rede, k)\n",
        "    fit[i,0] = resultado['acc']\n",
        "\n",
        "  return fit"
      ],
      "metadata": {
        "id": "j0bNiWA02NU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit = fitness_pop(Pop, X, y, med_rede, k)\n",
        "Pop = np.hstack([Pop,fit])"
      ],
      "metadata": {
        "id": "q336CDgv7V-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqSiIRAP8HWo",
        "outputId": "7f313810-004e-4231-9aac-7449f1ef8851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
              "        0.61587302],\n",
              "       [0.        , 0.        , 0.        , ..., 1.        , 1.        ,\n",
              "        0.62063492],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.63809524],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.58809524],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
              "        0.59126984],\n",
              "       [1.        , 0.        , 0.        , ..., 1.        , 1.        ,\n",
              "        0.6031746 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PTnmxeDs8PXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iniciando o AG**"
      ],
      "metadata": {
        "id": "YjKmHhLe8PYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lim = 0\n",
        "T_cross = T_cross*Tpop\n",
        "#Taxa de crossover define o tanto de filhos novos, nesse caso 0.4 * 100 = 40 filhos novos\n",
        "while (lim <= Geracoes):\n",
        "  lim += 1\n",
        "\n",
        "  Qtd_f = int(T_cross/2)\n",
        "\n",
        "  filhos = np.zeros((int(Qtd_f*2), wavs.size))\n",
        "  filho1 = np.zeros((int(Qtd_f), wavs.size))\n",
        "  filho2 = np.zeros((int(Qtd_f), wavs.size))\n",
        "\n",
        "  for i in range(int(Qtd_f)):\n",
        "    selecao_torneio(Pop, 4, Tpop)\n",
        "    pai1 = selecao_torneio(Pop, 4, Tpop)\n",
        "    pai2 = selecao_torneio(Pop, 4, Tpop) #Crossover com tamanho T_cross, definido como 40% da população dos pais da populacao\n",
        "    filho1[i],filho2[i] = crossover(pai1[:-1], pai2[:-1])\n",
        "\n",
        "  filhos = np.vstack([filho1,filho2])\n",
        "  filhos = Mutacao(filhos, Taxa_mut)\n",
        "\n",
        "  fit_filhos = fitness_pop(filhos, X, y, med_rede, k)\n",
        "  filhos = np.hstack([filhos,fit_filhos])\n",
        "\n",
        "  Nova_pop = np.vstack([Pop,filhos]) # Reinsercao\n",
        "  Nova_pop_sorted = Nova_pop[:,-1].argsort()\n",
        "  Nova_pop_sorted = Nova_pop_sorted[::-1]\n",
        "  Pop = Nova_pop[Nova_pop_sorted][0:Tpop, :] # Atualiza pop pegando os N melhores individuos\n",
        "\n",
        "  print(\"Geração: \", lim, \"Melhor fitness: \", max(Pop[:,-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJodX8_P8TFR",
        "outputId": "24d197f3-a6f1-4caa-a3a4-1142da24d462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geração:  1 Melhor fitness:  0.6380952380952378\n",
            "Mutacao\n",
            "Geração:  2 Melhor fitness:  0.6380952380952378\n",
            "Mutacao\n",
            "Geração:  3 Melhor fitness:  0.6380952380952378\n",
            "Mutacao\n",
            "Geração:  4 Melhor fitness:  0.6380952380952378\n",
            "Mutacao\n",
            "Geração:  5 Melhor fitness:  0.6380952380952378\n",
            "Mutacao\n",
            "Geração:  6 Melhor fitness:  0.6380952380952378\n",
            "Geração:  7 Melhor fitness:  0.6380952380952378\n",
            "Geração:  8 Melhor fitness:  0.6380952380952378\n",
            "Geração:  9 Melhor fitness:  0.6380952380952378\n",
            "Geração:  10 Melhor fitness:  0.6380952380952378\n",
            "Mutacao\n",
            "Geração:  11 Melhor fitness:  0.6380952380952378\n"
          ]
        }
      ]
    }
  ]
}